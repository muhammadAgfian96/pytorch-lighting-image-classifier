{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "# sys.path.append('/workspace')\n",
    "from clearml import StorageManager, Dataset\n",
    "# from config.default import TrainingConfig\n",
    "# from config.list_optimizer import ListOptimizer\n",
    "# conf = TrainingConfig()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vars(ListOptimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 10,\n",
       " 'learning_rate': 0.0001,\n",
       " 'opt_name': 'AdamW',\n",
       " 'opt_weight_decay': 0,\n",
       " 'opt_momentum': 0.9}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import asdict, dataclass, fields\n",
    "asdict(conf)['hyp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manage Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target path \"/home/agfian/shared/hdd_2/common-project/classifier/pytorch-lighting-image-classifier/src/notebooks/app-data-workflow/dataset-dev/Bousteud/feedback-Bousteud-2023-02-26_keep-drop/keep-drop\" does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m manager \u001b[39m=\u001b[39m StorageManager()\n\u001b[0;32m----> 2\u001b[0m manager\u001b[39m.\u001b[39mdownload_folder(\n\u001b[1;32m      3\u001b[0m     remote_url\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mapp-data-workflow/dataset-dev/Bousteud/feedback-Bousteud-2023-02-26_keep-drop/keep-drop\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     local_folder\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./dataset/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/clearml-task/lib/python3.10/site-packages/clearml/storage/manager.py:398\u001b[0m, in \u001b[0;36mStorageManager.download_folder\u001b[0;34m(cls, remote_url, local_folder, match_wildcard, overwrite, skip_zero_size_check, silence_errors)\u001b[0m\n\u001b[1;32m    395\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[1;32m    397\u001b[0m \u001b[39mwith\u001b[39;00m ThreadPool() \u001b[39mas\u001b[39;00m pool:\n\u001b[0;32m--> 398\u001b[0m     \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m helper\u001b[39m.\u001b[39;49mlist(prefix\u001b[39m=\u001b[39;49mremote_url):\n\u001b[1;32m    399\u001b[0m         remote_path \u001b[39m=\u001b[39m (\n\u001b[1;32m    400\u001b[0m             \u001b[39mstr\u001b[39m(Path(helper\u001b[39m.\u001b[39mbase_url) \u001b[39m/\u001b[39m Path(path))\n\u001b[1;32m    401\u001b[0m             \u001b[39mif\u001b[39;00m helper\u001b[39m.\u001b[39mget_driver_direct_access(helper\u001b[39m.\u001b[39mbase_url)\n\u001b[1;32m    402\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(helper\u001b[39m.\u001b[39mbase_url\u001b[39m.\u001b[39mrstrip(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m), path\u001b[39m.\u001b[39mlstrip(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    403\u001b[0m         )\n\u001b[1;32m    404\u001b[0m         \u001b[39mif\u001b[39;00m match_wildcard \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m fnmatch\u001b[39m.\u001b[39mfnmatch(remote_path, match_wildcard):\n",
      "File \u001b[0;32m~/.conda/envs/clearml-task/lib/python3.10/site-packages/clearml/storage/helper.py:796\u001b[0m, in \u001b[0;36mStorageHelper.list\u001b[0;34m(self, prefix, with_metadata)\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[39mif\u001b[39;00m prefix\u001b[39m.\u001b[39mstartswith(\u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_driver\u001b[39m.\u001b[39mbase_path)):\n\u001b[1;32m    795\u001b[0m         prefix \u001b[39m=\u001b[39m prefix[\u001b[39mlen\u001b[39m(\u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_driver\u001b[39m.\u001b[39mbase_path)):]\n\u001b[0;32m--> 796\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_driver\u001b[39m.\u001b[39;49mlist_container_objects(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_container, ex_prefix\u001b[39m=\u001b[39;49mprefix)\n\u001b[1;32m    797\u001b[0m result \u001b[39m=\u001b[39m [\n\u001b[1;32m    798\u001b[0m     obj\u001b[39m.\u001b[39mname \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m with_metadata \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_object_metadata(obj)\n\u001b[1;32m    799\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m res\n\u001b[1;32m    800\u001b[0m ]\n\u001b[1;32m    802\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_url \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfile://\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/clearml-task/lib/python3.10/site-packages/clearml/storage/helper.py:2830\u001b[0m, in \u001b[0;36m_FileStorageDriver.list_container_objects\u001b[0;34m(self, container, ex_prefix, **kwargs)\u001b[0m\n\u001b[1;32m   2829\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlist_container_objects\u001b[39m(\u001b[39mself\u001b[39m, container, ex_prefix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2830\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterate_container_objects(container, prefix\u001b[39m=\u001b[39;49mex_prefix))\n",
      "File \u001b[0;32m~/.conda/envs/clearml-task/lib/python3.10/site-packages/clearml/storage/helper.py:2501\u001b[0m, in \u001b[0;36m_FileStorageDriver._get_objects\u001b[0;34m(self, container, prefix)\u001b[0m\n\u001b[1;32m   2496\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_objects\u001b[39m(\u001b[39mself\u001b[39m, container, prefix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2497\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2498\u001b[0m \u001b[39m    Recursively iterate through the file-system and return the object names\u001b[39;00m\n\u001b[1;32m   2499\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2501\u001b[0m     cpath \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_container_cdn_url(container, check\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   2502\u001b[0m     \u001b[39mif\u001b[39;00m prefix:\n\u001b[1;32m   2503\u001b[0m         cpath \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m prefix\n",
      "File \u001b[0;32m~/.conda/envs/clearml-task/lib/python3.10/site-packages/clearml/storage/helper.py:2557\u001b[0m, in \u001b[0;36m_FileStorageDriver.get_container_cdn_url\u001b[0;34m(self, container, check)\u001b[0m\n\u001b[1;32m   2554\u001b[0m path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mrealpath(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_path, container\u001b[39m.\u001b[39mname \u001b[39mif\u001b[39;00m container \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m   2556\u001b[0m \u001b[39mif\u001b[39;00m check \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(path):\n\u001b[0;32m-> 2557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTarget path \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m does not exist\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(path))\n\u001b[1;32m   2559\u001b[0m \u001b[39mreturn\u001b[39;00m path\n",
      "\u001b[0;31mValueError\u001b[0m: Target path \"/home/agfian/shared/hdd_2/common-project/classifier/pytorch-lighting-image-classifier/src/notebooks/app-data-workflow/dataset-dev/Bousteud/feedback-Bousteud-2023-02-26_keep-drop/keep-drop\" does not exist"
     ]
    }
   ],
   "source": [
    "manager = StorageManager()\n",
    "manager.download_folder(\n",
    "    remote_url='app-data-workflow/dataset-dev/Bousteud/feedback-Bousteud-2023-02-26_keep-drop/keep-drop',\n",
    "    local_folder='./dataset/',\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML results page: http://10.8.0.10:7080/projects/e3ab1f2c806947eea2ea59994d35ec50/experiments/411403ce990b433aaeac743d154d52a2/output/log\n",
      "ClearML dataset page: http://10.8.0.10:7080/datasets/simple/e3ab1f2c806947eea2ea59994d35ec50/experiments/411403ce990b433aaeac743d154d52a2\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset.create(\n",
    "    dataset_project='fruit-oil',\n",
    "    dataset_name='sample-data-bousteud', \n",
    "    dataset_tags=['lerning-clearml'],\n",
    "    output_uri=f'{conf.OUTPUT_URI}/dataset/sample-from-clearml'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating SHA2 hash for 420 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [00:00<00:00, 4999.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash generation completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.add_files(path='/workspace/dataset/simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_folder = '/workspace/dataset/simple'\n",
    "counts = []\n",
    "folders = sorted(os.listdir(root_folder))\n",
    "for folder in folders:\n",
    "    count = len(os.listdir(os.path.join(root_folder, folder)))\n",
    "    counts.append([count])\n",
    "\n",
    "\n",
    "ds.get_logger().report_histogram(\n",
    "    title='Dataset Histogram',\n",
    "    series='Training Simple Dataset',\n",
    "    values=counts,\n",
    "    labels=folders,\n",
    "    xaxis='class',\n",
    "    yaxis='count of data'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pending uploads, starting dataset upload to s3://10.8.0.66:9000/clearml-test/dataset/sample-from-clearml\n",
      "Uploading dataset changes (420 files compressed to 69.21 MiB) to s3://10.8.0.66:9000/clearml-test/dataset/sample-from-clearml\n",
      "File compression and upload completed: total size 69.21 MiB, 1 chunk(s) stored (average size 69.21 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.finalize(auto_upload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://10.8.0.66:9000/clearml-test/dataset/sample-from-clearml'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.get_default_storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import albumentations as al\n",
    "from os.path import join\n",
    "from typing import Union\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as tt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def get_list_data(root_path, conf:TrainingConfig):\n",
    "\n",
    "    def check_health_img(fp):\n",
    "        try:\n",
    "            img = cv2.imread(fp)\n",
    "            h,w,c = img.shape\n",
    "            if h > 0 and w>0:\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            print('[ERROR] Image Corrupt: ', fp, e)\n",
    "            return False\n",
    "\n",
    "    def split_list(ls_fp_image):\n",
    "        count_imgs = len(ls_fp_image)\n",
    "        tr_count = int(tr*count_imgs)\n",
    "        va_count = int(va*count_imgs)\n",
    "        shuffle(ls_fp_image)\n",
    "        train = ls_fp_image[:tr_count]\n",
    "        val = ls_fp_image[tr_count:tr_count+va_count]\n",
    "        test = ls_fp_image[tr_count+va_count:]\n",
    "        return train, val, test\n",
    "    \n",
    "    d_metadata = {\n",
    "        'ratio': [],\n",
    "        'counts' : {\n",
    "            'train': {},\n",
    "            'val': {},\n",
    "            'test': {},\n",
    "        }\n",
    "    }\n",
    "\n",
    "    labels = conf.data.category\n",
    "    d_data = {lbl:[] for lbl in labels}\n",
    "    ls_train = []\n",
    "    ls_val = []\n",
    "    ls_test = []\n",
    "\n",
    "    for label in labels:\n",
    "        fp_folder = join(root_path, label)\n",
    "        for file in os.listdir(fp_folder):\n",
    "            fp_image = join(fp_folder, file)\n",
    "            if check_health_img(fp_image):\n",
    "                d_data[label].append((fp_image, labels.index(label)))\n",
    "    \n",
    "    tr = conf.data.train_ratio\n",
    "    va = conf.data.val_ratio\n",
    "    te = conf.data.test_ration\n",
    "    \n",
    "    d_metadata['ratio'] = [tr, va, te]\n",
    "\n",
    "    ls_train_set, ls_val_set, ls_test_set = [], [], []\n",
    "    for key, ls_fp_image in d_data.items():\n",
    "        ls_train, ls_val, ls_test = split_list(ls_fp_image)\n",
    "        ls_train_set.extend(ls_train)\n",
    "        ls_val_set.extend(ls_val)\n",
    "        ls_test_set.extend(ls_test)\n",
    "        d_metadata['counts']['train'][key] = len(ls_train)\n",
    "        d_metadata['counts']['val'][key] = len(ls_train)\n",
    "        d_metadata['counts']['test'][key] = len(ls_train)\n",
    "\n",
    "    d_metadata['train_count'] = len(ls_train_set)\n",
    "    d_metadata['val_count'] = len(ls_val_set)\n",
    "    d_metadata['test_count'] = len(ls_test_set)\n",
    "    \n",
    "    return ls_train_set, ls_val_set, ls_test_set, d_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDatasetBinsho(Dataset):\n",
    "    def __init__(self, data, transform):\n",
    "        self.data = data\n",
    "        self.transform = al.Compose(transform)\n",
    "\n",
    "    def __len__(self): return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        fp_img, y  = self.data[index]\n",
    "        y_label = torch.tensor(int(y))\n",
    "        x_image = np.array(Image.open(fp_img)) # rgb format!\n",
    "        x_image = self.transform(image=x_image)[\"image\"] \n",
    "        return x_image, y_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanstd(dl):\n",
    "    batch,sum_,sqr_= 0, 0, 0\n",
    "    for x,y in dl:\n",
    "        # print(type(x), x.shape, torch.min(x), torch.max(x))\n",
    "        sum_+=torch.mean(x,axis=[0,2,3])\n",
    "        sqr_+=torch.mean(x**2,axis=[0,2,3])\n",
    "        batch+=1\n",
    "    mean= sum_/batch\n",
    "    std= (sqr_/batch)-mean**2\n",
    "    print(mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs1 = ImageDatasetBinsho(root_path='/workspace/dataset/simple', conf=conf, transform=conf.aug.get_ls_val())\n",
    "len(imgs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Note - you must have torchvision installed for this example\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class ImageDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"./\"):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    \n",
    "    def setup(self, stage: str):\n",
    "        # get list of data\n",
    "        self.conf = TrainingConfig()\n",
    "        ls_train_set, ls_val_set, ls_test_set, d_metadata = get_list_data(root_path='/workspace/dataset/simple', conf=self.conf)\n",
    "        \n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\":\n",
    "            self.data_train = ImageDatasetBinsho(ls_train_set, transform=self.conf.aug.get_ls_train())\n",
    "            self.data_val = ImageDatasetBinsho(ls_val_set, transform=self.conf.aug.get_ls_train())\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\":\n",
    "            self.data_test = ImageDatasetBinsho(ls_test_set, transform=self.conf.aug.get_ls_train())\n",
    "\n",
    "    def train_dataloader(self):\n",
    "\n",
    "        return DataLoader(self.data_test, batch_size=self.conf.data.batch)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.data_val, batch_size=self.conf.data.batch)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.data_test, batch_size=self.conf.data.batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clearml-task",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba36c7a2ba5f7c9b23dc5bea081108fd1ea00a103930475a90b22d037c2ff72a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
