{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/workspace')\n",
    "from clearml import StorageManager, Dataset\n",
    "from config.default import TrainingConfig\n",
    "conf = TrainingConfig()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PROJECT_NAME': 'bousteud',\n",
       " 'TASK_NAME': 'maturity',\n",
       " 'TYPE_TASK': <TaskTypes.training: 'training'>,\n",
       " 'OUTPUT_URI': 's3://10.8.0.66:9000/clearml-test',\n",
       " 'db': {'bucket_experiment': 's3://10.8.0.66:9000/clearml-test/training/experiment',\n",
       "  'bucket_dataset': 's3://10.8.0.66:9000/clearml-test/dataset/simple'},\n",
       " 'data': {'random_seed': 76,\n",
       "  'dir': '/workspace/dataset/simple',\n",
       "  'batch': 24,\n",
       "  'train_ratio': 0.8,\n",
       "  'val_ratio': 0.1,\n",
       "  'test_ratio': 0.1,\n",
       "  'input_size': 224,\n",
       "  'input_resize': 256},\n",
       " 'aug': {'augmentor': 'albumentations',\n",
       "  'type_executions': 'online',\n",
       "  'augmentor_task': {'train': {'OneOf_1': [{'VerticalFlip': {'always_apply': False,\n",
       "       'p': 0.95}},\n",
       "     {'HorizontalFlip': {'always_apply': False, 'p': 0.95}}],\n",
       "    'ShiftScaleRotate': {'always_apply': True,\n",
       "     'p': 0.5,\n",
       "     'shift_limit_x': (-0.12, 0.12),\n",
       "     'shift_limit_y': (-0.12, 0.12),\n",
       "     'scale_limit': (-0.050000000000000044, 0.1499999999999999),\n",
       "     'rotate_limit': (-90, 90),\n",
       "     'interpolation': 0,\n",
       "     'border_mode': 0,\n",
       "     'value': [0, 0, 0],\n",
       "     'mask_value': None,\n",
       "     'rotate_method': 'largest_box'},\n",
       "    'CoarseDropout': {'always_apply': False,\n",
       "     'p': 0.5,\n",
       "     'max_holes': 25,\n",
       "     'max_height': 0.12,\n",
       "     'max_width': 0.12,\n",
       "     'min_holes': 16,\n",
       "     'min_height': 0.02,\n",
       "     'min_width': 0.02,\n",
       "     'fill_value': 0,\n",
       "     'mask_fill_value': None},\n",
       "    'RandomBrightnessContrast': {'always_apply': False,\n",
       "     'p': 0.5,\n",
       "     'brightness_limit': (-0.2, 0.45),\n",
       "     'contrast_limit': (-0.15, 0.35),\n",
       "     'brightness_by_max': False},\n",
       "    'OneOf_2': [{'MotionBlur': {'always_apply': False,\n",
       "       'p': 0.5,\n",
       "       'blur_limit': (3, 7)}},\n",
       "     {'ImageCompression': {'always_apply': False,\n",
       "       'p': 0.5,\n",
       "       'quality_lower': 99,\n",
       "       'quality_upper': 100,\n",
       "       'compression_type': 0}},\n",
       "     {'OpticalDistortion': {'always_apply': False,\n",
       "       'p': 0.5,\n",
       "       'distort_limit': (-0.05, 0.05),\n",
       "       'shift_limit': (-0.05, 0.05),\n",
       "       'interpolation': 1,\n",
       "       'border_mode': 4,\n",
       "       'value': None,\n",
       "       'mask_value': None}},\n",
       "     {'MultiplicativeNoise': {'always_apply': False,\n",
       "       'p': 0.5,\n",
       "       'multiplier': (0.9, 1.1),\n",
       "       'per_channel': False,\n",
       "       'elementwise': False}}],\n",
       "    'Resize': {'always_apply': True,\n",
       "     'p': 1,\n",
       "     'height': 224,\n",
       "     'width': 224,\n",
       "     'interpolation': 1},\n",
       "    'Normalize': {'always_apply': True,\n",
       "     'p': 1.0,\n",
       "     'mean': (0.5, 0.5, 0.5),\n",
       "     'std': (0.5, 0.5, 0.5),\n",
       "     'max_pixel_value': 255.0},\n",
       "    'ToTensorV2': {'always_apply': True, 'p': 1.0, 'transpose_mask': False}},\n",
       "   'val': {'Resize': {'always_apply': True,\n",
       "     'p': 1,\n",
       "     'height': 224,\n",
       "     'width': 224,\n",
       "     'interpolation': 1},\n",
       "    'Normalize': {'always_apply': True,\n",
       "     'p': 1.0,\n",
       "     'mean': (0.5, 0.5, 0.5),\n",
       "     'std': (0.5, 0.5, 0.5),\n",
       "     'max_pixel_value': 255.0},\n",
       "    'ToTensorV2': {'always_apply': True, 'p': 1.0, 'transpose_mask': True}}}},\n",
       " 'net': {'architecture': 'edgenext_x_small',\n",
       "  'pretrained': True,\n",
       "  'num_class': 5,\n",
       "  'resume': False,\n",
       "  'checkpoint_model': None},\n",
       " 'hyp': {'epoch': 35,\n",
       "  'learning_rate': 0.0001,\n",
       "  'opt_name': 'AdamW',\n",
       "  'opt_weight_decay': 0,\n",
       "  'opt_momentum': 0.9}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import asdict, dataclass, fields\n",
    "asdict(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manage Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'endpoint_url': 'http://10.8.0.66:9000', 'region_name': 'binsho-server-2', 'use_ssl': False, 'verify': True, 'config': <botocore.config.Config object at 0x7f7243f3fa10>, 'aws_access_key_id': 'agfian_test_1', 'aws_secret_access_key': 'clearml_secret_key_test'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/workspace/dataset/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager = StorageManager()\n",
    "manager.download_folder(\n",
    "    remote_url=conf.db.bucket_dataset,\n",
    "    local_folder='/workspace/dataset/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML results page: http://10.8.0.10:7080/projects/e3ab1f2c806947eea2ea59994d35ec50/experiments/411403ce990b433aaeac743d154d52a2/output/log\n",
      "ClearML dataset page: http://10.8.0.10:7080/datasets/simple/e3ab1f2c806947eea2ea59994d35ec50/experiments/411403ce990b433aaeac743d154d52a2\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset.create(\n",
    "    dataset_project='fruit-oil',\n",
    "    dataset_name='sample-data-bousteud', \n",
    "    dataset_tags=['lerning-clearml'],\n",
    "    output_uri=f'{conf.OUTPUT_URI}/dataset/sample-from-clearml'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating SHA2 hash for 420 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [00:00<00:00, 4999.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash generation completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.add_files(path='/workspace/dataset/simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_folder = '/workspace/dataset/simple'\n",
    "counts = []\n",
    "folders = sorted(os.listdir(root_folder))\n",
    "for folder in folders:\n",
    "    count = len(os.listdir(os.path.join(root_folder, folder)))\n",
    "    counts.append([count])\n",
    "\n",
    "\n",
    "ds.get_logger().report_histogram(\n",
    "    title='Dataset Histogram',\n",
    "    series='Training Simple Dataset',\n",
    "    values=counts,\n",
    "    labels=folders,\n",
    "    xaxis='class',\n",
    "    yaxis='count of data'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pending uploads, starting dataset upload to s3://10.8.0.66:9000/clearml-test/dataset/sample-from-clearml\n",
      "Uploading dataset changes (420 files compressed to 69.21 MiB) to s3://10.8.0.66:9000/clearml-test/dataset/sample-from-clearml\n",
      "File compression and upload completed: total size 69.21 MiB, 1 chunk(s) stored (average size 69.21 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.finalize(auto_upload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://10.8.0.66:9000/clearml-test/dataset/sample-from-clearml'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.get_default_storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import albumentations as al\n",
    "from os.path import join\n",
    "from typing import Union\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as tt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def get_list_data(root_path, conf:TrainingConfig):\n",
    "\n",
    "    def check_health_img(fp):\n",
    "        try:\n",
    "            img = cv2.imread(fp)\n",
    "            h,w,c = img.shape\n",
    "            if h > 0 and w>0:\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            print('[ERROR] Image Corrupt: ', fp, e)\n",
    "            return False\n",
    "\n",
    "    def split_list(ls_fp_image):\n",
    "        count_imgs = len(ls_fp_image)\n",
    "        tr_count = int(tr*count_imgs)\n",
    "        va_count = int(va*count_imgs)\n",
    "        shuffle(ls_fp_image)\n",
    "        train = ls_fp_image[:tr_count]\n",
    "        val = ls_fp_image[tr_count:tr_count+va_count]\n",
    "        test = ls_fp_image[tr_count+va_count:]\n",
    "        return train, val, test\n",
    "    \n",
    "    d_metadata = {\n",
    "        'ratio': [],\n",
    "        'counts' : {\n",
    "            'train': {},\n",
    "            'val': {},\n",
    "            'test': {},\n",
    "        }\n",
    "    }\n",
    "\n",
    "    labels = conf.data.category\n",
    "    d_data = {lbl:[] for lbl in labels}\n",
    "    ls_train = []\n",
    "    ls_val = []\n",
    "    ls_test = []\n",
    "\n",
    "    for label in labels:\n",
    "        fp_folder = join(root_path, label)\n",
    "        for file in os.listdir(fp_folder):\n",
    "            fp_image = join(fp_folder, file)\n",
    "            if check_health_img(fp_image):\n",
    "                d_data[label].append((fp_image, labels.index(label)))\n",
    "    \n",
    "    tr = conf.data.train_ratio\n",
    "    va = conf.data.val_ratio\n",
    "    te = conf.data.test_ration\n",
    "    \n",
    "    d_metadata['ratio'] = [tr, va, te]\n",
    "\n",
    "    ls_train_set, ls_val_set, ls_test_set = [], [], []\n",
    "    for key, ls_fp_image in d_data.items():\n",
    "        ls_train, ls_val, ls_test = split_list(ls_fp_image)\n",
    "        ls_train_set.extend(ls_train)\n",
    "        ls_val_set.extend(ls_val)\n",
    "        ls_test_set.extend(ls_test)\n",
    "        d_metadata['counts']['train'][key] = len(ls_train)\n",
    "        d_metadata['counts']['val'][key] = len(ls_train)\n",
    "        d_metadata['counts']['test'][key] = len(ls_train)\n",
    "\n",
    "    d_metadata['train_count'] = len(ls_train_set)\n",
    "    d_metadata['val_count'] = len(ls_val_set)\n",
    "    d_metadata['test_count'] = len(ls_test_set)\n",
    "    \n",
    "    return ls_train_set, ls_val_set, ls_test_set, d_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDatasetBinsho(Dataset):\n",
    "    def __init__(self, data, transform):\n",
    "        self.data = data\n",
    "        self.transform = al.Compose(transform)\n",
    "\n",
    "    def __len__(self): return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        fp_img, y  = self.data[index]\n",
    "        y_label = torch.tensor(int(y))\n",
    "        x_image = np.array(Image.open(fp_img)) # rgb format!\n",
    "        x_image = self.transform(image=x_image)[\"image\"] \n",
    "        return x_image, y_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanstd(dl):\n",
    "    batch,sum_,sqr_= 0, 0, 0\n",
    "    for x,y in dl:\n",
    "        # print(type(x), x.shape, torch.min(x), torch.max(x))\n",
    "        sum_+=torch.mean(x,axis=[0,2,3])\n",
    "        sqr_+=torch.mean(x**2,axis=[0,2,3])\n",
    "        batch+=1\n",
    "    mean= sum_/batch\n",
    "    std= (sqr_/batch)-mean**2\n",
    "    print(mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs1 = ImageDatasetBinsho(root_path='/workspace/dataset/simple', conf=conf, transform=conf.aug.get_ls_val())\n",
    "len(imgs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Note - you must have torchvision installed for this example\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class ImageDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"./\"):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    \n",
    "    def setup(self, stage: str):\n",
    "        # get list of data\n",
    "        self.conf = TrainingConfig()\n",
    "        ls_train_set, ls_val_set, ls_test_set, d_metadata = get_list_data(root_path='/workspace/dataset/simple', conf=self.conf)\n",
    "        \n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\":\n",
    "            self.data_train = ImageDatasetBinsho(ls_train_set, transform=self.conf.aug.get_ls_train())\n",
    "            self.data_val = ImageDatasetBinsho(ls_val_set, transform=self.conf.aug.get_ls_train())\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\":\n",
    "            self.data_test = ImageDatasetBinsho(ls_test_set, transform=self.conf.aug.get_ls_train())\n",
    "\n",
    "    def train_dataloader(self):\n",
    "\n",
    "        return DataLoader(self.data_test, batch_size=self.conf.data.batch)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.data_val, batch_size=self.conf.data.batch)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.data_test, batch_size=self.conf.data.batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
